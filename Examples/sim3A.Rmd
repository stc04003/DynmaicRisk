---
title: "Random landmark time with longitudinal predictors measured at times 1, 2, 3, 4, and 5."
data: August 15, 2022
output: html_document
---

```{r default, include = FALSE, collapse = TRUE}
library(knitr)
opts_chunk$set(prompt = TRUE, comment = "")
```

In the following example, we use the `ranger()` function implemented in `R` package `ranger` (Wright and Ziegler, 2017) to construct survival trees then apply the proposed ensemble method to compute the predicted survival probabilities.

## Generate simulated data

We consider a scenario where the event times are generated from an irreversible multi-state model with three states: healthy, diseased, and death. 
We assume that all subjects started in the healthy state, disease onset is an intermediate event, and death is
the event of interest. 
Suppose we are interested in predicting the survival probability among those who experienced an intermediate event, 
the target landmark probability is $$P(T\ge U + t|T\ge U, U, W(1, U), W(2, U), W(3, U), W(4, U), W(5, U), Z),$$
where $T$ is a continuous failure time, $U$ is the time to the intermediate event (time from the healthy state to the disease state), $W(U)$ is a $q$-dimensional vector of time-dependent predictors measured at times 1, 2, 3, 4, and 5, 
and $Z$ is a $p$-dimensional vector of baseline predictors.
In this case, the landmark time $T_L = U$. 


The following codes generate simulated data from `simDat3A()`. 
See vignette on
[generating simulated data](https://htmlpreview.github.io/?https://github.com/stc04003/DynmaicRisk/blob/main/Examples/data.html)
for the complete simulation settings and details of `simDat3A()`.
The following generates a data from `simDat3A()`.
```{R}
source("../codes/sim3A.R")
set.seed(1); dat <- simDat3A(n = 400, cen = .2)
```


## Construct trees with `ranger`

The following fits a random survival forest with `ranger()` with a minimum node size of 15.
```{R}
library(survival)
library(ranger)
(fit <- ranger(Surv(Time, status) ~ ., data = dat, min.node.size = 15))
```

## Calculate predicted survival probabilities with the proposed ensemble method

The following codes generate a testing data (`dat0`) and 
compute the predicted probabilities with the proposed ensemble procedure.
The testing data is generated by `simDat3A()` and the predicted survival is obtained by applying `getSurv()`.
See vignette on
[add-on functions for ensemble procedures](https://htmlpreview.github.io/?https://github.com/stc04003/DynmaicRisk/blob/main/Examples/addon.html)
for functions' descriptions.
```{R}
source("../codes/ranger-addon.R")
dat0 <- simDat3A(500, 0, T)
predS <- getSurv(fit, dat, dat0)
head(predS, 3)
```
The `getSurv()` function returns a list, whose $i$th member 
is the estimated survival function for the $i$th subject from the testing data, `dat0`.

## Evaluating model performance

Due to the complicated relationship between event times and longitudinal markers, deriving the closed-form expression of
the true probability is challenging. 
The `getTrueSurv3A()` function from `codes/sim3A.R` computes the true probability using 
Monte Carlo method for this scenario.
```{R}
trueS <- getTrueSurv3A(dat0)
```

The `getTrueSurv3A()` function returns a list, whose $i$th member is the
estimated survival function for the $i$th subject from the testing data. 
The following codes calculate the integrated mean absolute error and the integrated mean squared error (MSE)
to evaluate the model performance. 
```{R}
t0 <- seq(0, quantile(dat0$Time[dat0$status > 0], .9), .01)
## Intergrated absolute error
mean(sapply(1:nrow(dat0), function(i) abs(predS[[i]](t0) - trueS[[i]](t0))))
## Intergrated MSE
mean(sapply(1:nrow(dat0), function(i) (predS[[i]](t0) - trueS[[i]](t0))^2))
```

In addition, the concordance measure, which is equivalent to the area under 
the receiver operating characteristic (ROC) curve,
can also be used to evaluate the model performance. 
The cumulative concordance of the testing data can be computed as follows,
where `sc` is the Kaplan-Meier estimate of the censoring distribution.distribution.
```{R}
sc <- with(survfit(Surv(Time + D, 1 - status) ~ 1, data = dat), 
           stepfun(time, c(1, surv)))
mean(sapply(t0, getCON, predS, sc, dat0), na.rm = TRUE)
```

## Permutation variable importance

The permutation variable importance of a predictor is computed as the average decrease in 
model accuracy on the out-of-bag (OOB) samples when the respective feature values are randomly permuted.
We extend this idea to study variable importance in dynamic risk prediction using censored data. 

We first calculate the OOB cumulative concordance for prediction based on trees built without 
the $i$th subject via `getSi()`.
Each predictor of interest is randomly permuted to compute the permutation OOB cumulative concordance.
The OOB cumulative concordance measure is computed as follows. 
```{R}
con0 <- mean(sapply(t0, getCON2, getSi(fit, dat), sc, dat), na.rm = T)
```
The following generates 100 permutations for each predictor
and compute the corresponding OOB cumulative concordance.
```{R}
vnames <- c(paste("Z", 1:10, sep = "."), paste0("W.", 1:10, "."))
B <- 100
```

```{R, cache = TRUE, message = FALSE}
library(mcreplicate)
set.seed(0)
vimps <- sapply(1:length(vnames), function(i) 
  mc_replicate(B, {
    dat2 <- dat
    if (substr(vnames[i], 1, 1) == "Z")
      dat2[,vnames[i]] <- sample(dat2[,vnames[i]])
    else {
      permID <- grep(vnames[i], names(dat2))
      toPerm <- dat2[,permID[1]] > -1e5
      dat2[toPerm, permID] <- dat2[sample(which(toPerm)), permID]
    }
    f <- getSi(fit, dat2)
    mean(sapply(t0, getCON2, f, sc, dat2), na.rm = T)
  }))
```
Define the permutation variable importance as the average difference in OOB cumulative concordances over all permutations.
The following codes plot the permutation variable importance sorts by the median.
```{R, message = FALSE}
library(dplyr)
library(forcats)
library(ggplot2)
dd <- data.frame(vars = rep(vnames, each = B), vimp = con0 - c(vimps))
dd %>% mutate(vars = fct_reorder(vars, vimp, .fun = 'median')) %>% 
  ggplot(aes(x = vars, y = vimp)) + geom_boxplot() + 
  coord_flip() + xlab("") + ylab("")
```


## Reference 

- Wright, M. N. and Ziegler, A. (2017). `ranger`: A fast implementation of random forests for high dimensional
data in `C++` and `R`. Journal of Statistical Software 77 1â€“17.